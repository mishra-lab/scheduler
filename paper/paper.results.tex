\subsection{Software}
We developed a software package with a user interface that implements the above LP problem and allows configuration of clinicians at [ref \ref{???}], to be used by the ID division at St. Michael's Hospital. The software was used to generate the results in the following sections, using real data as well as simulated data as input.

\subsection{Infectious Diseases Division}  %main comment  = I think use past tense in writing
We used clinician time-off requests and minimum/maximum requirements from 2015-2018 as input data for the LP problem. Table \ref{tbl:2018-schedule-comparison} presents the optimal schedule generated using the software as well as the manually-created schedule for data from 2018. The schedule is color-coded to distinguish between the different clinicians assigned. \\

\include{tbl/2018_schedule_comparison}

First, we evaluated the software-generated schedule by comparing it with the manually-created schedule. Specifically, we examined the adherence of each schedule to the constraints presented in table \ref{tbl:constraint-summary}. As shown in table \ref{tbl:constraints-comparison}, the optimal schedule generated using the software satisfied all mandatory constraints. In contrast, the manually-created schedule was not able to satisfy all mandatory constraints. In particular, we see that the manual schedule assigned clinicians to multiple consecutive blocks in all four years. Moreover, the manual schedule did not have an equal distribution of weekends and holidays for all four years of data. Evaluating the objectives, we see that LP outperforms the manually created schedule in all four years, by accommodating almost all time-off requests and ensuring that weekends are always assigned close to blocks.

\include{tbl/constraints_comparison}

\subsection{Simulations}
We then examined the properties of the LP problem using simulated data. Specifically, we examined the influence of expanding the following parameters on the runtime of the algorithm: number of clinicians; number of services offered in the division; amount of time-off requests per clinician throughout the year. We also examined the effect of a longer time-horizon on the runtime. \\

%We begin by evaluating the runtime in a single-division department, with an increasing number of clinicians, over a 1-year time-span. Figure \ref{fig:avg-runtime-clinicians} shows the average runtime in seconds of 10 runs, for different numbers of clinicians, $C = \{5, 10, 15, 25, 50, 100\}$. From the graph, we can see that the LP formulation performs extremely well on a typical hospital department with no more than 30 clinicians [ref \ref{??}], and can even handle busier departments with upwards of 100 clinicians. \\

%\begin{figure}[h]
%	\centering
%	\includegraphics[scale=.7]{fig/avg_runtime_clinicians}
%	\caption{Plot of average runtime for LP with an increasing number of clinicians}
%	\label{fig:avg-runtime-clinicians}
%\end{figure}

%Next we evaluate the effect of increasing the number of departments. Figure \ref{fig:avg-runtime-divisions} shows the average runtime for a department with 10 clinicians, and a range of divisions, $D = \{1, 2, 3\}$. We can see that increasing the number of divisions even by 2 greatly affects the runtime. The LP solver had significant trouble when we increased the number of divisions further, making it impractical to quickly generate schedules for departments with many divisions. \\

%\begin{figure}[h]
%	\centering
%	\includegraphics[scale=.7]{fig/avg_runtime_divisions}
%	\caption{Plot of average runtime for LP with an increasing number of divisions}
%	\label{fig:avg-runtime-divisions}
%\end{figure}

The effect of an increasing number of requests per clinician on the average runtime of the LP solver is shown in figure \ref{fig:avg-runtime-requests}. We executed the program on a single-division department with 10 clinicians, and $R = \abs{\mathcal{WR}} + \abs{\mathcal{BR}} = \{1, 2, 3, 5, 10\}$ non-overlapping requests per clinician. The increase in the number of requests did not affect the runtime of the LP solver, indicating that it can accommodate a lot of flexibility in clinician requests. \\

\begin{figure}[h]
	\centering
	\includegraphics[scale=.7]{fig/avg_runtime_requests}
	\caption{Average runtime for LP with an increasing number of requests per clinician}
	\label{fig:avg-runtime-requests}
\end{figure}

Figure \ref{fig:avg-runtime-blocks} presents the average runtime over 10 runs for an increasing number of 2-week blocks $B = \{26, 52, 78, 104\}$ to simulate a department that generates schedules for a few years in advance. Although here was an increasing trend in the runtime, the solver was able to find an optimal schedule for all time horizons in under XX amount of time. \\ % 'very reasonable amount of time" is vague. what is reasonable? better to give a range in value.

\begin{figure}[h]
	\centering
	\includegraphics[scale=.7]{fig/avg_runtime_blocks}
	\caption{Average runtime for LP with an increasing number of 2-week blocks}
	\label{fig:avg-runtime-blocks}
\end{figure}

The effect of increasing the number of services %divisions %do you mean services?
on the runtime of the program is shown in Table \ref{tbl:runtime-services-clinicians-comparison}. We executed the algorithm for $S = \{1, 2, 3\}$ total services and $C = \{10, 20, 30, 50\}$ clinicians in total across all services. For 2 or more services, a roster of more than XX clinicians becomes impractical to schedule, as searching requires more than 24 hours. However, when relaxing the `No Consecutive Blocks' constraint, we see a great improvement in runtime for 2 and 3 services, and we are able to generate a schedule with upwards of 50 clinicians in under XX amount of time.  %what does division mean? do you mean services?

\include{tbl/runtime_services_clinicians}